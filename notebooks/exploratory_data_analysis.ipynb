{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "In this notebook performed exploratory data analysis of the dataset\n",
    "Lets download all the libraries"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Load the ground truth annotations"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "annotations_df = pd.read_csv('../data/train_ship_segmentations.csv')\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Perform exploratory data analysis on the dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"Dataset shape:\", annotations_df.shape)\n",
    "print(\"Number of unique images:\", annotations_df['ImageId'].nunique())\n",
    "print(\"Number of annotated ships:\", annotations_df['EncodedPixels'].count())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Analyze the distribution of ship vs. non-ship images"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ship_count = annotations_df['EncodedPixels'].count()\n",
    "no_ship_count = annotations_df['ImageId'].nunique() - ship_count\n",
    "labels = ['Ships', 'No Ships']\n",
    "sizes = [ship_count, no_ship_count]\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.pie(sizes, labels=labels, autopct='%1.1f%%', startangle=90)\n",
    "plt.axis('equal')\n",
    "plt.title('Distribution of Ships vs. No Ships')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Calculate statistics and insights from the dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ships_per_image = annotations_df.groupby('ImageId')['EncodedPixels'].count().mean()\n",
    "print(\"Average ships per image:\", ships_per_image)\n",
    "annotations_df['Size'] = annotations_df['EncodedPixels'].apply(lambda x: len(x.split()))\n",
    "size_distribution = annotations_df.groupby('Size')['ImageId'].count()\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(size_distribution.index, size_distribution.values)\n",
    "plt.xlabel('Ship Size')\n",
    "plt.ylabel('Number of Ships')\n",
    "plt.title('Ship Size Distribution')\n",
    "plt.xticks(range(1, 20))\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Visualize sample images and corresponding masks"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sample_images = annotations_df.sample(n=4)\n",
    "plt.figure(figsize=(12, 8))\n",
    "for i, row in sample_images.iterrows():\n",
    "    image_id = row['ImageId']\n",
    "    mask = row['EncodedPixels']\n",
    "\n",
    "    # Load and plot the image\n",
    "    image_path = f'../data/train_v2/{image_id}'\n",
    "    image = plt.imread(image_path)\n",
    "    plt.subplot(2, 4, i+1)\n",
    "    plt.imshow(image)\n",
    "    plt.axis('off')\n",
    "    plt.title(f'Image: {image_id}')\n",
    "\n",
    "    # Plot the corresponding mask\n",
    "    plt.subplot(2, 4, i+5)\n",
    "    plt.imshow(mask, cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.title('Mask')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Since the datasets have mostly photos without ships, this may affect the construction of the training model. Since there will be much less data with ships, the model may tend to show low sensitivity to ships or reject them all as background noise."
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
